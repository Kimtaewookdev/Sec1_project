{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kimtaewookdev/Sec1_project/blob/main/n411/n411_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzIdLqSrQNwo"
      },
      "source": [
        "<img src='https://user-images.githubusercontent.com/6457691/90080969-0f758d00-dd47-11ea-8191-fa12fd2054a7.png' width = '200' align = 'right'>\n",
        "\n",
        "## *DATA SCIENCE / SECTION 4 / SPRINT 1 / NOTE 1 - assignmnet*\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# N411. 퍼셉트론(Perceptron)과 인공신경망(Artificial Neural Networks) 과제"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade xlrd"
      ],
      "metadata": {
        "id": "FLpOFZOVNPEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLmkc-CilNSB"
      },
      "source": [
        "## 단층 퍼셉트론"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOgsgcnLlNSC"
      },
      "source": [
        "이진분류 태스크를 위한 예시 데이터를 생성해보겠습니다. X 데이터는 (x좌표, y좌표)로 이루어져 있으며, 타겟 데이터는 0과 1로 이루어져 있습니다.\n",
        "\n",
        "아래의 예시 생성 부분이 당장 이해 안가도 괜찮습니다. 넘파이를 활용해, 이런 다양한 일들을 할 수 있다는 점을 알아두시고, 궁금하신 분은 나중에 더 찾아보세요.\n",
        "\n",
        "- np.append, np.vstack, np.hstack의 각각의 차이점에 대해 더 찾아보세요!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "as85O459lNSC",
        "outputId": "6c2cbb0a-1ce6-44f1-d862-5ead7aaf10a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "np.random.seed(0)\n",
        "\n",
        "x11 = np.random.uniform(low=0, high=5, size=(50,))\n",
        "x12 = np.random.uniform(low=10, high=15, size=(50,))\n",
        "x21 = np.random.uniform(low=0, high=5, size=(50,))\n",
        "x22 = np.random.uniform(low=10, high=15, size=(50,))\n",
        "\n",
        "\n",
        "x1 = np.append(x11, x12)\n",
        "x2 = np.append(x21, x22)\n",
        "\n",
        "y11 = np.random.uniform(low=10, high=15, size=(50,))\n",
        "y12 = np.random.uniform(low=0, high=5, size=(50,))\n",
        "y21 = np.random.uniform(low=0, high=5, size=(50,))\n",
        "y22 = np.random.uniform(low=10, high=15, size=(50,))\n",
        "\n",
        "y1 = np.append(y11, y12)\n",
        "y2 = np.append(y21, y22)\n",
        "\n",
        "x_1 = np.vstack([x1, y1]).T\n",
        "x_2 = np.vstack([x2, y2]).T\n",
        "y_1 = np.ones_like(x_1[:, 0])\n",
        "y_2 = np.zeros_like(x_2[:, 0])\n",
        "x = np.vstack([x_1, x_2])\n",
        "y = np.hstack([y_1, y_2])\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (12,5))\n",
        "ax.plot(x_1[:, 0], x_1[:,1], 'bo')\n",
        "ax.plot(x_2[:,0], x_2[:,1], 'ro')\n",
        "ax.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo8TDLtNlNSE"
      },
      "source": [
        "### 문제 1-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBqL9B5-lNSF"
      },
      "source": [
        "단층 퍼셉트론으로 위의 문제를 해결할 수 없음을 확인해보겠습니다. 이진 분류를 위한 단층 퍼셉트론을 구현하기 위해 다음 빈칸에 들어갈 내용으로 알맞은 것은?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wvs1YkYdlNSF",
        "outputId": "d510bb74-1983-44ce-8642-1d6bb68c10d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 1.7042 - accuracy: 0.6150\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.1792 - accuracy: 0.6200\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.9453 - accuracy: 0.5750\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.8170 - accuracy: 0.4500\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.7530 - accuracy: 0.4400\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.7192 - accuracy: 0.4050\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7113 - accuracy: 0.5250\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7043 - accuracy: 0.4300\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6999 - accuracy: 0.4200\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.4900\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x, y, epochs=10)\n",
        "\n",
        "# 각각의 변수 명을 모두 다르게 설정했습니다.\n",
        "# model.predict의 결과값 / preds_1d / pred_class 의 형태(shape)와 값들을 한번 직접 확인해보세요\n",
        "\n",
        "preds = model.predict(x)\n",
        "preds_1d = preds.flatten()\n",
        "pred_class = np.where(preds_1d > 0.5, 1 , 0)\n",
        "\n",
        "y_true = x[pred_class==1]\n",
        "y_false = x[pred_class==0]\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (12,5))\n",
        "ax.plot(y_true[:, 0], y_true[:,1], 'bo')\n",
        "ax.plot(y_false[:,0], y_false[:,1], 'ro')\n",
        "ax.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvZ9nmwmlNSG"
      },
      "source": [
        "### 문제 1-2\n",
        "비선형성이 추가되지 않은 단층 퍼셉트론이 어떠한 결정 경계를 만드나요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvNvoQJk-xb-"
      },
      "source": [
        "## 문제2. 실제 데이터 과제\n",
        " - 아래 주어진 데이터를 신경망을 이용하여 Classification 문제를 풀어보세요.\n",
        " - 또한 머신러닝에서 배운 방법(배우지 않은 머신러닝 방법론(SVM 등)도 가능)을 이용하여 비교해보세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqOkgM9wnmNu"
      },
      "source": [
        "입력 데이터 샘플과 Features : 1077 샘플 x 69 Features (변수)\n",
        "\n",
        "데이터 label: 다운증후군 (1), 정상군 (2)\n",
        "\n",
        "데이터는 다운증후군과 정상군 마우스 피질의 핵 분획에서 검출 가능한 신호를 생성하는 69 개 단백질의 발현 수준으로 구성되어 있습니다.\n",
        "라벨로는 다운증후군 1, 정상군 2로 할당되어 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gULuO1ETO-6G"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel(\"https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/MouseProtein/mouse_protein_X.xls\", header=None)\n",
        "df_label = pd.read_excel(\"https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/MouseProtein/mouse_protein_label.xls\", header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "6I-8OQ_APLtG",
        "outputId": "5018513f-4847-4092-d249-65e8aa6f9cc5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0        1        2       3       4        5        6       7   \\\n",
              "0  0.50364  0.74719  0.43018  2.8163  5.9902  0.21883  0.17757  2.3737   \n",
              "1  0.51462  0.68906  0.41177  2.7895  5.6850  0.21164  0.17282  2.2921   \n",
              "2  0.50918  0.73025  0.41831  2.6872  5.6221  0.20901  0.17572  2.2833   \n",
              "3  0.44211  0.61708  0.35863  2.4669  4.9795  0.22289  0.17646  2.1523   \n",
              "4  0.43494  0.61743  0.35880  2.3658  4.7187  0.21311  0.17363  2.1340   \n",
              "\n",
              "        8       9   ...       59       60       61      62      63       64  \\\n",
              "0  0.23222  1.7509  ...  0.14276  0.43096  0.24754  1.6033  2.0149  0.10823   \n",
              "1  0.22697  1.5964  ...  0.14204  0.45716  0.25763  1.6717  2.0046  0.10975   \n",
              "2  0.23025  1.5613  ...  0.14244  0.51047  0.25534  1.6635  2.0168  0.10820   \n",
              "3  0.20700  1.5951  ...  0.14507  0.43100  0.25110  1.4846  1.9572  0.11988   \n",
              "4  0.19216  1.5042  ...  0.14087  0.48123  0.25177  1.5348  2.0091  0.11952   \n",
              "\n",
              "        65       66       67      68  \n",
              "0  1.04500  0.83156  0.18885  1.6757  \n",
              "1  1.00990  0.84927  0.20040  1.7436  \n",
              "2  0.99685  0.84671  0.19368  1.9264  \n",
              "3  0.99022  0.83328  0.19211  1.7006  \n",
              "4  0.99777  0.87867  0.20560  1.8397  \n",
              "\n",
              "[5 rows x 69 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f04f55d-619f-4e3f-9867-078a1f882e98\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.50364</td>\n",
              "      <td>0.74719</td>\n",
              "      <td>0.43018</td>\n",
              "      <td>2.8163</td>\n",
              "      <td>5.9902</td>\n",
              "      <td>0.21883</td>\n",
              "      <td>0.17757</td>\n",
              "      <td>2.3737</td>\n",
              "      <td>0.23222</td>\n",
              "      <td>1.7509</td>\n",
              "      <td>...</td>\n",
              "      <td>0.14276</td>\n",
              "      <td>0.43096</td>\n",
              "      <td>0.24754</td>\n",
              "      <td>1.6033</td>\n",
              "      <td>2.0149</td>\n",
              "      <td>0.10823</td>\n",
              "      <td>1.04500</td>\n",
              "      <td>0.83156</td>\n",
              "      <td>0.18885</td>\n",
              "      <td>1.6757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.51462</td>\n",
              "      <td>0.68906</td>\n",
              "      <td>0.41177</td>\n",
              "      <td>2.7895</td>\n",
              "      <td>5.6850</td>\n",
              "      <td>0.21164</td>\n",
              "      <td>0.17282</td>\n",
              "      <td>2.2921</td>\n",
              "      <td>0.22697</td>\n",
              "      <td>1.5964</td>\n",
              "      <td>...</td>\n",
              "      <td>0.14204</td>\n",
              "      <td>0.45716</td>\n",
              "      <td>0.25763</td>\n",
              "      <td>1.6717</td>\n",
              "      <td>2.0046</td>\n",
              "      <td>0.10975</td>\n",
              "      <td>1.00990</td>\n",
              "      <td>0.84927</td>\n",
              "      <td>0.20040</td>\n",
              "      <td>1.7436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.50918</td>\n",
              "      <td>0.73025</td>\n",
              "      <td>0.41831</td>\n",
              "      <td>2.6872</td>\n",
              "      <td>5.6221</td>\n",
              "      <td>0.20901</td>\n",
              "      <td>0.17572</td>\n",
              "      <td>2.2833</td>\n",
              "      <td>0.23025</td>\n",
              "      <td>1.5613</td>\n",
              "      <td>...</td>\n",
              "      <td>0.14244</td>\n",
              "      <td>0.51047</td>\n",
              "      <td>0.25534</td>\n",
              "      <td>1.6635</td>\n",
              "      <td>2.0168</td>\n",
              "      <td>0.10820</td>\n",
              "      <td>0.99685</td>\n",
              "      <td>0.84671</td>\n",
              "      <td>0.19368</td>\n",
              "      <td>1.9264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.44211</td>\n",
              "      <td>0.61708</td>\n",
              "      <td>0.35863</td>\n",
              "      <td>2.4669</td>\n",
              "      <td>4.9795</td>\n",
              "      <td>0.22289</td>\n",
              "      <td>0.17646</td>\n",
              "      <td>2.1523</td>\n",
              "      <td>0.20700</td>\n",
              "      <td>1.5951</td>\n",
              "      <td>...</td>\n",
              "      <td>0.14507</td>\n",
              "      <td>0.43100</td>\n",
              "      <td>0.25110</td>\n",
              "      <td>1.4846</td>\n",
              "      <td>1.9572</td>\n",
              "      <td>0.11988</td>\n",
              "      <td>0.99022</td>\n",
              "      <td>0.83328</td>\n",
              "      <td>0.19211</td>\n",
              "      <td>1.7006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.43494</td>\n",
              "      <td>0.61743</td>\n",
              "      <td>0.35880</td>\n",
              "      <td>2.3658</td>\n",
              "      <td>4.7187</td>\n",
              "      <td>0.21311</td>\n",
              "      <td>0.17363</td>\n",
              "      <td>2.1340</td>\n",
              "      <td>0.19216</td>\n",
              "      <td>1.5042</td>\n",
              "      <td>...</td>\n",
              "      <td>0.14087</td>\n",
              "      <td>0.48123</td>\n",
              "      <td>0.25177</td>\n",
              "      <td>1.5348</td>\n",
              "      <td>2.0091</td>\n",
              "      <td>0.11952</td>\n",
              "      <td>0.99777</td>\n",
              "      <td>0.87867</td>\n",
              "      <td>0.20560</td>\n",
              "      <td>1.8397</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 69 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f04f55d-619f-4e3f-9867-078a1f882e98')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f04f55d-619f-4e3f-9867-078a1f882e98 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f04f55d-619f-4e3f-9867-078a1f882e98');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# 샘플당 100개의 특성(feature)을 가진 데이터\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrIvw52rPdx4",
        "outputId": "434f9330-ee38-4490-fa2a-2ee5e5e7a18d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   0\n",
            "0  1\n",
            "1  1\n",
            "2  1\n",
            "3  1\n",
            "4  1\n",
            "      0\n",
            "1072  2\n",
            "1073  2\n",
            "1074  2\n",
            "1075  2\n",
            "1076  2\n"
          ]
        }
      ],
      "source": [
        "print(df_label.head())\n",
        "print(df_label.tail())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow import keras\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df, df_label-1, test_size=0.2, random_state=42)\n",
        "\n",
        "model_nn = tf.keras.Sequential(\n",
        "    [\n",
        "     keras.layers.Dense(1, activation='sigmoid')\n",
        "    ]\n",
        ")\n",
        "\n",
        "model_nn.compile(optimizer='sgd',\n",
        "              loss='binary_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_nn.fit(x_train, y_train, epochs=500)\n",
        "\n",
        "y_prob = model_nn.predict(x_test).flatten()\n",
        "y_pred = np.where(y_prob > 0.5, 1, 0)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "RteDOIbINmmM",
        "outputId": "2771e3ee-8e07-4d0a-f2a4-476ff6d47eaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "27/27 [==============================] - 1s 3ms/step - loss: 0.7590 - accuracy: 0.5134\n",
            "Epoch 2/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7059 - accuracy: 0.5099\n",
            "Epoch 3/500\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.6995 - accuracy: 0.5343\n",
            "Epoch 4/500\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.6938 - accuracy: 0.5470\n",
            "Epoch 5/500\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.6879 - accuracy: 0.5447\n",
            "Epoch 6/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6828 - accuracy: 0.5633\n",
            "Epoch 7/500\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.6791 - accuracy: 0.5645\n",
            "Epoch 8/500\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.6751 - accuracy: 0.5889\n",
            "Epoch 9/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6707 - accuracy: 0.5970\n",
            "Epoch 10/500\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.6697 - accuracy: 0.6028\n",
            "Epoch 11/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6636 - accuracy: 0.6051\n",
            "Epoch 12/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6597 - accuracy: 0.6225\n",
            "Epoch 13/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6582 - accuracy: 0.6086\n",
            "Epoch 14/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6540 - accuracy: 0.6202\n",
            "Epoch 15/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6517 - accuracy: 0.6411\n",
            "Epoch 16/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6499 - accuracy: 0.6225\n",
            "Epoch 17/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6144\n",
            "Epoch 18/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6444 - accuracy: 0.6225\n",
            "Epoch 19/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6444 - accuracy: 0.6307\n",
            "Epoch 20/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6426 - accuracy: 0.6167\n",
            "Epoch 21/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6392 - accuracy: 0.6295\n",
            "Epoch 22/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6371 - accuracy: 0.6179\n",
            "Epoch 23/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6361 - accuracy: 0.6400\n",
            "Epoch 24/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6348 - accuracy: 0.6260\n",
            "Epoch 25/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6325 - accuracy: 0.6481\n",
            "Epoch 26/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6308 - accuracy: 0.6376\n",
            "Epoch 27/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6299 - accuracy: 0.6318\n",
            "Epoch 28/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.6492\n",
            "Epoch 29/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6265 - accuracy: 0.6376\n",
            "Epoch 30/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6251 - accuracy: 0.6446\n",
            "Epoch 31/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.6434\n",
            "Epoch 32/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.6492\n",
            "Epoch 33/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6227 - accuracy: 0.6388\n",
            "Epoch 34/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6199 - accuracy: 0.6388\n",
            "Epoch 35/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6188 - accuracy: 0.6469\n",
            "Epoch 36/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6188 - accuracy: 0.6400\n",
            "Epoch 37/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6173 - accuracy: 0.6492\n",
            "Epoch 38/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6165 - accuracy: 0.6353\n",
            "Epoch 39/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.6504\n",
            "Epoch 40/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6138 - accuracy: 0.6620\n",
            "Epoch 41/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6128 - accuracy: 0.6434\n",
            "Epoch 42/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6117 - accuracy: 0.6562\n",
            "Epoch 43/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6123 - accuracy: 0.6516\n",
            "Epoch 44/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6096 - accuracy: 0.6678\n",
            "Epoch 45/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6093 - accuracy: 0.6446\n",
            "Epoch 46/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6088 - accuracy: 0.6609\n",
            "Epoch 47/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6087 - accuracy: 0.6423\n",
            "Epoch 48/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6086 - accuracy: 0.6481\n",
            "Epoch 49/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6082 - accuracy: 0.6504\n",
            "Epoch 50/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6056 - accuracy: 0.6527\n",
            "Epoch 51/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6050 - accuracy: 0.6678\n",
            "Epoch 52/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6026 - accuracy: 0.6597\n",
            "Epoch 53/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6046 - accuracy: 0.6458\n",
            "Epoch 54/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6038 - accuracy: 0.6597\n",
            "Epoch 55/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6026 - accuracy: 0.6388\n",
            "Epoch 56/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6007 - accuracy: 0.6516\n",
            "Epoch 57/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6000 - accuracy: 0.6643\n",
            "Epoch 58/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5994 - accuracy: 0.6492\n",
            "Epoch 59/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5992 - accuracy: 0.6551\n",
            "Epoch 60/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6003 - accuracy: 0.6458\n",
            "Epoch 61/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5981 - accuracy: 0.6574\n",
            "Epoch 62/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5960 - accuracy: 0.6632\n",
            "Epoch 63/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5969 - accuracy: 0.6562\n",
            "Epoch 64/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5961 - accuracy: 0.6609\n",
            "Epoch 65/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5951 - accuracy: 0.6574\n",
            "Epoch 66/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5939 - accuracy: 0.6574\n",
            "Epoch 67/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5921 - accuracy: 0.6690\n",
            "Epoch 68/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5930 - accuracy: 0.6632\n",
            "Epoch 69/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5925 - accuracy: 0.6725\n",
            "Epoch 70/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5921 - accuracy: 0.6551\n",
            "Epoch 71/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5914 - accuracy: 0.6702\n",
            "Epoch 72/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.6574\n",
            "Epoch 73/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5903 - accuracy: 0.6713\n",
            "Epoch 74/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5898 - accuracy: 0.6597\n",
            "Epoch 75/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5899 - accuracy: 0.6643\n",
            "Epoch 76/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5853 - accuracy: 0.6690\n",
            "Epoch 77/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.6551\n",
            "Epoch 78/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5873 - accuracy: 0.6655\n",
            "Epoch 79/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5864 - accuracy: 0.6643\n",
            "Epoch 80/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5860 - accuracy: 0.6678\n",
            "Epoch 81/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5858 - accuracy: 0.6783\n",
            "Epoch 82/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5843 - accuracy: 0.6725\n",
            "Epoch 83/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.6667\n",
            "Epoch 84/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5821 - accuracy: 0.6632\n",
            "Epoch 85/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5834 - accuracy: 0.6678\n",
            "Epoch 86/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.6736\n",
            "Epoch 87/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.6690\n",
            "Epoch 88/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.6725\n",
            "Epoch 89/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.6713\n",
            "Epoch 90/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.6678\n",
            "Epoch 91/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.6609\n",
            "Epoch 92/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.6794\n",
            "Epoch 93/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.6655\n",
            "Epoch 94/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.6702\n",
            "Epoch 95/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.6794\n",
            "Epoch 96/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5772 - accuracy: 0.6667\n",
            "Epoch 97/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.6748\n",
            "Epoch 98/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5759 - accuracy: 0.6783\n",
            "Epoch 99/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5765 - accuracy: 0.6760\n",
            "Epoch 100/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5749 - accuracy: 0.6760\n",
            "Epoch 101/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5756 - accuracy: 0.6794\n",
            "Epoch 102/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5748 - accuracy: 0.6794\n",
            "Epoch 103/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5751 - accuracy: 0.6736\n",
            "Epoch 104/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5734 - accuracy: 0.6783\n",
            "Epoch 105/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.6771\n",
            "Epoch 106/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5720 - accuracy: 0.6771\n",
            "Epoch 107/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5723 - accuracy: 0.6748\n",
            "Epoch 108/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.6760\n",
            "Epoch 109/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5705 - accuracy: 0.6783\n",
            "Epoch 110/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5706 - accuracy: 0.6794\n",
            "Epoch 111/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.6852\n",
            "Epoch 112/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5701 - accuracy: 0.6748\n",
            "Epoch 113/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.6829\n",
            "Epoch 114/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.6748\n",
            "Epoch 115/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.6852\n",
            "Epoch 116/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5691 - accuracy: 0.6934\n",
            "Epoch 117/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.6864\n",
            "Epoch 118/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.6794\n",
            "Epoch 119/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5678 - accuracy: 0.6852\n",
            "Epoch 120/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5671 - accuracy: 0.6841\n",
            "Epoch 121/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5665 - accuracy: 0.6829\n",
            "Epoch 122/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.6852\n",
            "Epoch 123/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.6864\n",
            "Epoch 124/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.6864\n",
            "Epoch 125/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.6945\n",
            "Epoch 126/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.6876\n",
            "Epoch 127/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5644 - accuracy: 0.6876\n",
            "Epoch 128/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.6864\n",
            "Epoch 129/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.6957\n",
            "Epoch 130/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.6934\n",
            "Epoch 131/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.6887\n",
            "Epoch 132/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5607 - accuracy: 0.6841\n",
            "Epoch 133/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5619 - accuracy: 0.6841\n",
            "Epoch 134/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.6876\n",
            "Epoch 135/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5595 - accuracy: 0.6899\n",
            "Epoch 136/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.6957\n",
            "Epoch 137/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.6934\n",
            "Epoch 138/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5588 - accuracy: 0.7050\n",
            "Epoch 139/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.6911\n",
            "Epoch 140/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.6852\n",
            "Epoch 141/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.6945\n",
            "Epoch 142/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.6992\n",
            "Epoch 143/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.6911\n",
            "Epoch 144/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.6945\n",
            "Epoch 145/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.6969\n",
            "Epoch 146/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.6945\n",
            "Epoch 147/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.6829\n",
            "Epoch 148/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5544 - accuracy: 0.6934\n",
            "Epoch 149/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.6945\n",
            "Epoch 150/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.6969\n",
            "Epoch 151/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5534 - accuracy: 0.6934\n",
            "Epoch 152/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.6957\n",
            "Epoch 153/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.6957\n",
            "Epoch 154/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.6957\n",
            "Epoch 155/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.6934\n",
            "Epoch 156/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.7027\n",
            "Epoch 157/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7027\n",
            "Epoch 158/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.6969\n",
            "Epoch 159/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7062\n",
            "Epoch 160/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.6980\n",
            "Epoch 161/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.7062\n",
            "Epoch 162/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.6899\n",
            "Epoch 163/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.6980\n",
            "Epoch 164/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7038\n",
            "Epoch 165/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7038\n",
            "Epoch 166/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.6980\n",
            "Epoch 167/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.7050\n",
            "Epoch 168/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7085\n",
            "Epoch 169/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5478 - accuracy: 0.7015\n",
            "Epoch 170/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7096\n",
            "Epoch 171/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7027\n",
            "Epoch 172/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7038\n",
            "Epoch 173/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7027\n",
            "Epoch 174/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7027\n",
            "Epoch 175/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.6980\n",
            "Epoch 176/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.7062\n",
            "Epoch 177/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7073\n",
            "Epoch 178/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.7050\n",
            "Epoch 179/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7050\n",
            "Epoch 180/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7027\n",
            "Epoch 181/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7108\n",
            "Epoch 182/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7085\n",
            "Epoch 183/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.6992\n",
            "Epoch 184/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7131\n",
            "Epoch 185/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.7108\n",
            "Epoch 186/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7062\n",
            "Epoch 187/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7096\n",
            "Epoch 188/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7131\n",
            "Epoch 189/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7062\n",
            "Epoch 190/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7108\n",
            "Epoch 191/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7073\n",
            "Epoch 192/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7050\n",
            "Epoch 193/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5393 - accuracy: 0.7166\n",
            "Epoch 194/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7189\n",
            "Epoch 195/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5388 - accuracy: 0.7166\n",
            "Epoch 196/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.7131\n",
            "Epoch 197/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7096\n",
            "Epoch 198/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7143\n",
            "Epoch 199/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.7120\n",
            "Epoch 200/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7120\n",
            "Epoch 201/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.6969\n",
            "Epoch 202/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.7154\n",
            "Epoch 203/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7178\n",
            "Epoch 204/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5364 - accuracy: 0.7178\n",
            "Epoch 205/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7131\n",
            "Epoch 206/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7131\n",
            "Epoch 207/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.7213\n",
            "Epoch 208/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7166\n",
            "Epoch 209/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7096\n",
            "Epoch 210/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7085\n",
            "Epoch 211/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.7247\n",
            "Epoch 212/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7143\n",
            "Epoch 213/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.7236\n",
            "Epoch 214/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7189\n",
            "Epoch 215/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7213\n",
            "Epoch 216/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.7166\n",
            "Epoch 217/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.7143\n",
            "Epoch 218/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.7166\n",
            "Epoch 219/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5313 - accuracy: 0.7108\n",
            "Epoch 220/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7213\n",
            "Epoch 221/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7178\n",
            "Epoch 222/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7224\n",
            "Epoch 223/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7340\n",
            "Epoch 224/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7271\n",
            "Epoch 225/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7247\n",
            "Epoch 226/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7224\n",
            "Epoch 227/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7271\n",
            "Epoch 228/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.7259\n",
            "Epoch 229/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7189\n",
            "Epoch 230/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7271\n",
            "Epoch 231/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7305\n",
            "Epoch 232/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7213\n",
            "Epoch 233/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7271\n",
            "Epoch 234/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.7213\n",
            "Epoch 235/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7329\n",
            "Epoch 236/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7282\n",
            "Epoch 237/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.7305\n",
            "Epoch 238/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7271\n",
            "Epoch 239/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7305\n",
            "Epoch 240/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7247\n",
            "Epoch 241/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5255 - accuracy: 0.7259\n",
            "Epoch 242/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7259\n",
            "Epoch 243/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.7236\n",
            "Epoch 244/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.7247\n",
            "Epoch 245/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7282\n",
            "Epoch 246/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7340\n",
            "Epoch 247/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7166\n",
            "Epoch 248/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7317\n",
            "Epoch 249/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7166\n",
            "Epoch 250/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7329\n",
            "Epoch 251/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7294\n",
            "Epoch 252/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7259\n",
            "Epoch 253/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7364\n",
            "Epoch 254/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7375\n",
            "Epoch 255/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7282\n",
            "Epoch 256/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7259\n",
            "Epoch 257/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7340\n",
            "Epoch 258/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7271\n",
            "Epoch 259/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7282\n",
            "Epoch 260/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7329\n",
            "Epoch 261/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7364\n",
            "Epoch 262/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7329\n",
            "Epoch 263/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7352\n",
            "Epoch 264/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7364\n",
            "Epoch 265/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7352\n",
            "Epoch 266/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7317\n",
            "Epoch 267/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7282\n",
            "Epoch 268/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7271\n",
            "Epoch 269/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7259\n",
            "Epoch 270/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7375\n",
            "Epoch 271/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7340\n",
            "Epoch 272/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7340\n",
            "Epoch 273/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7340\n",
            "Epoch 274/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7398\n",
            "Epoch 275/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7387\n",
            "Epoch 276/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7317\n",
            "Epoch 277/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7294\n",
            "Epoch 278/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7259\n",
            "Epoch 279/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7398\n",
            "Epoch 280/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7282\n",
            "Epoch 281/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7422\n",
            "Epoch 282/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7387\n",
            "Epoch 283/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7387\n",
            "Epoch 284/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7387\n",
            "Epoch 285/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7352\n",
            "Epoch 286/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7282\n",
            "Epoch 287/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7433\n",
            "Epoch 288/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7352\n",
            "Epoch 289/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7398\n",
            "Epoch 290/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7387\n",
            "Epoch 291/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7364\n",
            "Epoch 292/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7422\n",
            "Epoch 293/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7445\n",
            "Epoch 294/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7433\n",
            "Epoch 295/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7375\n",
            "Epoch 296/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7387\n",
            "Epoch 297/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7329\n",
            "Epoch 298/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7352\n",
            "Epoch 299/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7398\n",
            "Epoch 300/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7387\n",
            "Epoch 301/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7387\n",
            "Epoch 302/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7387\n",
            "Epoch 303/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7515\n",
            "Epoch 304/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7422\n",
            "Epoch 305/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7387\n",
            "Epoch 306/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7480\n",
            "Epoch 307/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7387\n",
            "Epoch 308/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7410\n",
            "Epoch 309/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7422\n",
            "Epoch 310/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7433\n",
            "Epoch 311/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7468\n",
            "Epoch 312/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7375\n",
            "Epoch 313/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7398\n",
            "Epoch 314/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7364\n",
            "Epoch 315/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7340\n",
            "Epoch 316/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7480\n",
            "Epoch 317/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7456\n",
            "Epoch 318/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7491\n",
            "Epoch 319/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7503\n",
            "Epoch 320/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7410\n",
            "Epoch 321/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7491\n",
            "Epoch 322/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7468\n",
            "Epoch 323/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7480\n",
            "Epoch 324/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7387\n",
            "Epoch 325/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7491\n",
            "Epoch 326/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7491\n",
            "Epoch 327/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7422\n",
            "Epoch 328/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7398\n",
            "Epoch 329/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7410\n",
            "Epoch 330/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7491\n",
            "Epoch 331/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7515\n",
            "Epoch 332/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7503\n",
            "Epoch 333/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.7468\n",
            "Epoch 334/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7491\n",
            "Epoch 335/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7491\n",
            "Epoch 336/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.7491\n",
            "Epoch 337/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7480\n",
            "Epoch 338/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.7456\n",
            "Epoch 339/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7515\n",
            "Epoch 340/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7445\n",
            "Epoch 341/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7456\n",
            "Epoch 342/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7468\n",
            "Epoch 343/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.7468\n",
            "Epoch 344/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7526\n",
            "Epoch 345/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.7422\n",
            "Epoch 346/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.7468\n",
            "Epoch 347/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.7538\n",
            "Epoch 348/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7538\n",
            "Epoch 349/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.7538\n",
            "Epoch 350/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7433\n",
            "Epoch 351/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.7433\n",
            "Epoch 352/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7491\n",
            "Epoch 353/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7526\n",
            "Epoch 354/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.7526\n",
            "Epoch 355/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7480\n",
            "Epoch 356/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7480\n",
            "Epoch 357/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.7491\n",
            "Epoch 358/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.7480\n",
            "Epoch 359/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7526\n",
            "Epoch 360/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.7480\n",
            "Epoch 361/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.7515\n",
            "Epoch 362/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.7561\n",
            "Epoch 363/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.7515\n",
            "Epoch 364/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7538\n",
            "Epoch 365/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7549\n",
            "Epoch 366/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.7503\n",
            "Epoch 367/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.7526\n",
            "Epoch 368/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.7491\n",
            "Epoch 369/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.7526\n",
            "Epoch 370/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7503\n",
            "Epoch 371/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7549\n",
            "Epoch 372/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.7515\n",
            "Epoch 373/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4939 - accuracy: 0.7607\n",
            "Epoch 374/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.7549\n",
            "Epoch 375/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7538\n",
            "Epoch 376/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7503\n",
            "Epoch 377/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.7584\n",
            "Epoch 378/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7503\n",
            "Epoch 379/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7561\n",
            "Epoch 380/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7503\n",
            "Epoch 381/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7526\n",
            "Epoch 382/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.7468\n",
            "Epoch 383/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.7549\n",
            "Epoch 384/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.7561\n",
            "Epoch 385/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.7549\n",
            "Epoch 386/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.7538\n",
            "Epoch 387/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.7573\n",
            "Epoch 388/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.7573\n",
            "Epoch 389/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7538\n",
            "Epoch 390/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7654\n",
            "Epoch 391/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.7480\n",
            "Epoch 392/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.7549\n",
            "Epoch 393/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7596\n",
            "Epoch 394/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7654\n",
            "Epoch 395/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7642\n",
            "Epoch 396/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7596\n",
            "Epoch 397/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7538\n",
            "Epoch 398/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.7549\n",
            "Epoch 399/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7526\n",
            "Epoch 400/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7561\n",
            "Epoch 401/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7607\n",
            "Epoch 402/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7561\n",
            "Epoch 403/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.7561\n",
            "Epoch 404/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7596\n",
            "Epoch 405/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7526\n",
            "Epoch 406/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.7596\n",
            "Epoch 407/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7607\n",
            "Epoch 408/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.7607\n",
            "Epoch 409/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.7596\n",
            "Epoch 410/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7573\n",
            "Epoch 411/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7607\n",
            "Epoch 412/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7596\n",
            "Epoch 413/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7666\n",
            "Epoch 414/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.7631\n",
            "Epoch 415/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7642\n",
            "Epoch 416/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7503\n",
            "Epoch 417/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7642\n",
            "Epoch 418/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7584\n",
            "Epoch 419/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7607\n",
            "Epoch 420/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7758\n",
            "Epoch 421/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7712\n",
            "Epoch 422/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7666\n",
            "Epoch 423/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7607\n",
            "Epoch 424/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7607\n",
            "Epoch 425/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7607\n",
            "Epoch 426/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7700\n",
            "Epoch 427/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7654\n",
            "Epoch 428/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7584\n",
            "Epoch 429/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7654\n",
            "Epoch 430/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4821 - accuracy: 0.7642\n",
            "Epoch 431/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7677\n",
            "Epoch 432/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.7607\n",
            "Epoch 433/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4821 - accuracy: 0.7607\n",
            "Epoch 434/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7549\n",
            "Epoch 435/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7642\n",
            "Epoch 436/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7666\n",
            "Epoch 437/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.7654\n",
            "Epoch 438/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.7596\n",
            "Epoch 439/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7677\n",
            "Epoch 440/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7642\n",
            "Epoch 441/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7747\n",
            "Epoch 442/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7607\n",
            "Epoch 443/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7619\n",
            "Epoch 444/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7666\n",
            "Epoch 445/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7642\n",
            "Epoch 446/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7654\n",
            "Epoch 447/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7724\n",
            "Epoch 448/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7677\n",
            "Epoch 449/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7561\n",
            "Epoch 450/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7770\n",
            "Epoch 451/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7561\n",
            "Epoch 452/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7677\n",
            "Epoch 453/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.7770\n",
            "Epoch 454/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7793\n",
            "Epoch 455/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7677\n",
            "Epoch 456/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7758\n",
            "Epoch 457/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7677\n",
            "Epoch 458/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7619\n",
            "Epoch 459/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7735\n",
            "Epoch 460/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.7724\n",
            "Epoch 461/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7689\n",
            "Epoch 462/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7747\n",
            "Epoch 463/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7573\n",
            "Epoch 464/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7619\n",
            "Epoch 465/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7735\n",
            "Epoch 466/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7758\n",
            "Epoch 467/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7689\n",
            "Epoch 468/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7677\n",
            "Epoch 469/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7712\n",
            "Epoch 470/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7654\n",
            "Epoch 471/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7735\n",
            "Epoch 472/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7677\n",
            "Epoch 473/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7724\n",
            "Epoch 474/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7735\n",
            "Epoch 475/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7607\n",
            "Epoch 476/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7770\n",
            "Epoch 477/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7700\n",
            "Epoch 478/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7700\n",
            "Epoch 479/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7747\n",
            "Epoch 480/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7747\n",
            "Epoch 481/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7689\n",
            "Epoch 482/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7886\n",
            "Epoch 483/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7666\n",
            "Epoch 484/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7747\n",
            "Epoch 485/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7735\n",
            "Epoch 486/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7700\n",
            "Epoch 487/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7770\n",
            "Epoch 488/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7747\n",
            "Epoch 489/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7724\n",
            "Epoch 490/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.7689\n",
            "Epoch 491/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7828\n",
            "Epoch 492/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7724\n",
            "Epoch 493/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7747\n",
            "Epoch 494/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7758\n",
            "Epoch 495/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7770\n",
            "Epoch 496/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7758\n",
            "Epoch 497/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.7805\n",
            "Epoch 498/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7735\n",
            "Epoch 499/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7840\n",
            "Epoch 500/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.7793\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.84      0.80       119\n",
            "           1       0.78      0.69      0.73        97\n",
            "\n",
            "    accuracy                           0.77       216\n",
            "   macro avg       0.77      0.77      0.77       216\n",
            "weighted avg       0.77      0.77      0.77       216\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model_ml = RandomForestClassifier(n_estimators=250, min_samples_leaf=3)\n",
        "\n",
        "model_ml.fit(x_train, y_train.values.ravel())\n",
        "\n",
        "y_pred_ml = model_ml.predict(x_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred_ml))"
      ],
      "metadata": {
        "id": "W1JUmxXrYod8",
        "outputId": "bfa053a5-61ef-42b7-875b-b77a5920a41e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       119\n",
            "           1       1.00      0.95      0.97        97\n",
            "\n",
            "    accuracy                           0.98       216\n",
            "   macro avg       0.98      0.97      0.98       216\n",
            "weighted avg       0.98      0.98      0.98       216\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yilj1IY3M4Zr"
      },
      "source": [
        "---\n",
        "\n",
        "4-1. 사용한 모델을 입력합니다. \n",
        "\n",
        "4-2. Accuracy를 입력합니다. \n",
        "\n",
        "4-3. Precision 을 입력합니다. \n",
        "\n",
        "4-4. Recall 을 입력합니다.\n",
        "\n",
        "4-5. F1 score 를 입력합니다. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ds_cs_N421a.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}